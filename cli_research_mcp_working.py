#!/usr/bin/env python3
"""
å·¥ä½œç‰ˆæœ¬ï¼šåŸºäºMCPçš„æœ¬åœ°æ–‡ä»¶ç ”ç©¶è„šæœ¬
ä½¿ç”¨æ–¹æ³•: python cli_research_mcp_working.py "ç ”ç©¶é—®é¢˜" --docs-path "./test_docs"
"""

import os
import argparse
import asyncio
import uuid
from datetime import datetime
from langchain_mcp_adapters.client import MultiServerMCPClient

async def run_mcp_local_research(question: str, docs_path: str):
    """åŸºäºMCPçš„æœ¬åœ°æ–‡ä»¶ç ”ç©¶ - ç®€åŒ–ç‰ˆæœ¬ç›´æ¥ä½¿ç”¨MCPå·¥å…·"""

    # éªŒè¯æ–‡æ¡£è·¯å¾„
    if not os.path.exists(docs_path):
        print(f"é”™è¯¯: æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨: {docs_path}")
        return None

    abs_docs_path = os.path.abspath(docs_path)
    print(f"ç ”ç©¶é—®é¢˜: {question}")
    print(f"æ–‡æ¡£è·¯å¾„: {abs_docs_path}")
    print("=" * 60)

    # MCPé…ç½® - ä½¿ç”¨æˆ‘ä»¬æµ‹è¯•æˆåŠŸçš„æ ¼å¼
    mcp_config = {
        "filesystem": {
            "transport": "stdio",
            "command": "npx",
            "args": ["@modelcontextprotocol/server-filesystem", abs_docs_path]
        }
    }

    print("åˆ›å»ºMCPå®¢æˆ·ç«¯...")
    try:
        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        client = MultiServerMCPClient(mcp_config)

        # è·å–å·¥å…·
        tools = await client.get_tools()
        print(f"âœ… æˆåŠŸè¿æ¥ï¼Œè·å¾— {len(tools)} ä¸ªMCPå·¥å…·")

        # è·å–å·¥å…·å¼•ç”¨
        list_tool = next((t for t in tools if t.name == "list_directory"), None)
        read_tool = next((t for t in tools if t.name == "read_text_file"), None)

        if not list_tool or not read_tool:
            print("âŒ ç¼ºå°‘å¿…è¦çš„MCPå·¥å…·")
            return

        # ç¬¬ä¸€æ­¥ï¼šåˆ—å‡ºå¯ç”¨æ–‡ä»¶
        print("\nğŸ“ æ‰«æå¯ç”¨æ–‡ä»¶...")
        try:
            # ä½¿ç”¨æˆ‘ä»¬æµ‹è¯•æˆåŠŸçš„è·¯å¾„æ ¼å¼
            base_dir = os.path.basename(abs_docs_path)
            files_result = await list_tool.ainvoke({"path": base_dir})
            print(f"å‘ç°æ–‡ä»¶: {files_result}")
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ—å‡ºæ–‡ä»¶: {e}")
            return

        # ç¬¬äºŒæ­¥ï¼šè¯»å–æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        print("\nğŸ“– è¯»å–æ–‡ä»¶å†…å®¹...")
        file_contents = {}

        # æ ¹æ®æ–‡ä»¶åˆ—è¡¨æå–æ–‡ä»¶å
        file_names = []
        for line in files_result.split('\n'):
            if '[FILE]' in line:
                # æå–æ–‡ä»¶å
                file_name = line.split('[FILE]')[1].strip()
                file_names.append(file_name)

        for file_name in file_names:
            try:
                # ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„æ ¼å¼
                file_path = f"{base_dir}/{file_name}"
                print(f"  è¯»å–æ–‡ä»¶: {file_path}")
                content = await read_tool.ainvoke({"path": file_path})
                file_contents[file_name] = content
                print(f"  âœ… æˆåŠŸè¯»å– {file_name} ({len(content)} å­—ç¬¦)")
            except Exception as e:
                print(f"  âŒ è¯»å– {file_name} å¤±è´¥: {e}")

        # ç¬¬ä¸‰æ­¥ï¼šåŸºäºæ–‡ä»¶å†…å®¹ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆç ”ç©¶æŠ¥å‘Š...")
        report = generate_research_report(question, file_contents)

        # ç¬¬å››æ­¥ï¼šä¿å­˜æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"mcp_research_report_{timestamp}.md"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"\nğŸ“Š ç ”ç©¶æŠ¥å‘Š:")
        print("=" * 60)
        print(report)
        print("=" * 60)
        print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

        return report

    except Exception as e:
        print(f"âŒ MCPç ”ç©¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_research_report(question: str, file_contents: dict) -> str:
    """åŸºäºæ–‡ä»¶å†…å®¹ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""

    report = f"""# æœ¬åœ°æ–‡æ¡£ç ”ç©¶æŠ¥å‘Š

**ç ”ç©¶é—®é¢˜**: {question}
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**æ•°æ®æ¥æº**: æœ¬åœ°MCPæ–‡ä»¶ç³»ç»Ÿ

---

## ğŸ“Š æ•°æ®æ¦‚è§ˆ

åŸºäºä»¥ä¸‹æœ¬åœ°æ–‡ä»¶è¿›è¡Œç ”ç©¶åˆ†æï¼š
"""

    # æ·»åŠ æ–‡ä»¶æ¦‚è§ˆ
    for filename, content in file_contents.items():
        report += f"- **{filename}**: {len(content)} å­—ç¬¦\n"

    report += "\n---\n\n## ğŸ“‹ è¯¦ç»†åˆ†æ\n\n"

    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    for filename, content in file_contents.items():
        report += f"### ğŸ“„ {filename}\n\n"

        if filename.endswith('.md'):
            # Markdownæ–‡ä»¶ - æå–å…³é”®ä¿¡æ¯
            lines = content.split('\n')
            headers = [line for line in lines if line.startswith('#')]
            if headers:
                report += "**ä¸»è¦ç« èŠ‚**:\n"
                for header in headers[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªæ ‡é¢˜
                    report += f"- {header.strip()}\n"

            # æå–å‰å‡ æ®µå†…å®¹
            paragraphs = [p.strip() for p in content.split('\n\n') if p.strip() and not p.startswith('#')]
            if paragraphs:
                report += f"\n**å†…å®¹æ‘˜è¦**: {paragraphs[0][:300]}...\n\n"

        elif filename.endswith('.csv'):
            # CSVæ–‡ä»¶ - åˆ†ææ•°æ®ç»“æ„
            lines = content.split('\n')
            if lines:
                header = lines[0]
                report += f"**æ•°æ®ç»“æ„**: {header}\n"
                report += f"**æ•°æ®è¡Œæ•°**: {len(lines) - 1}\n"

                # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
                if len(lines) > 1:
                    report += "\n**æ ·æœ¬æ•°æ®**:\n```\n"
                    for line in lines[1:min(6, len(lines))]:  # æ˜¾ç¤ºå‰5è¡Œæ•°æ®
                        if line.strip():
                            report += f"{line}\n"
                    report += "```\n\n"

        else:
            # å…¶ä»–æ–‡ä»¶ç±»å‹ - æ˜¾ç¤ºå‰å‡ è¡Œ
            lines = content.split('\n')
            report += f"**æ–‡ä»¶ç±»å‹**: {filename.split('.')[-1] if '.' in filename else 'æœªçŸ¥'}\n"
            report += f"**å†…å®¹é¢„è§ˆ**: {content[:200]}...\n\n"

    # æ·»åŠ ç»¼åˆåˆ†æ
    report += "---\n\n## ğŸ” ç»¼åˆåˆ†æ\n\n"

    if question.lower() in ['æ€»ç»“æœ¬åœ°æ–‡æ¡£å†…å®¹', 'æ–‡æ¡£å†…å®¹æ€»ç»“', 'æœ¬åœ°æ–‡æ¡£æ€»ç»“']:
        report += "æ ¹æ®æ‰«æçš„æœ¬åœ°æ–‡æ¡£ï¼Œå‘ç°ä»¥ä¸‹ä¸»è¦å†…å®¹:\n\n"

        # åŸºäºæ–‡ä»¶å†…å®¹è¿›è¡Œç®€å•çš„å…³é”®è¯åˆ†æ
        all_content = ' '.join(file_contents.values()).lower()

        if 'ai' in all_content or 'äººå·¥æ™ºèƒ½' in all_content:
            report += "- ğŸ¤– **äººå·¥æ™ºèƒ½ç›¸å…³**: æ–‡æ¡£åŒ…å«AIå‘å±•å†å²å’ŒæŠ€æœ¯ä¿¡æ¯\n"

        if 'æ—¶é—´' in all_content or 'å¹´ä»½' in all_content or 'year' in all_content:
            report += "- ğŸ“… **æ—¶é—´çº¿ä¿¡æ¯**: åŒ…å«å†å²å‘å±•æ—¶é—´çº¿æ•°æ®\n"

        if 'csv' in str(file_contents.keys()).lower():
            report += "- ğŸ“Š **ç»“æ„åŒ–æ•°æ®**: åŒ…å«CSVæ ¼å¼çš„æ•°æ®æ–‡ä»¶\n"

        if 'md' in str(file_contents.keys()).lower():
            report += "- ğŸ“ **æ–‡æ¡£è¯´æ˜**: åŒ…å«Markdownæ ¼å¼çš„è¯´æ˜æ–‡æ¡£\n"

    else:
        # é’ˆå¯¹ç‰¹å®šé—®é¢˜çš„åˆ†æ
        report += f"é’ˆå¯¹é—®é¢˜ã€Œ{question}ã€çš„åˆ†æ:\n\n"
        report += "åŸºäºæœ¬åœ°æ–‡æ¡£å†…å®¹ï¼Œå¯ä»¥æä¾›ä»¥ä¸‹ç›¸å…³ä¿¡æ¯:\n\n"

        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        for filename, content in file_contents.items():
            relevant_content = []
            for line in content.split('\n'):
                # ç®€å•çš„ç›¸å…³æ€§æ£€æŸ¥
                question_words = question.lower().split()
                if any(word in line.lower() for word in question_words if len(word) > 2):
                    relevant_content.append(line.strip())

            if relevant_content:
                report += f"**ä» {filename} ä¸­æ‰¾åˆ°çš„ç›¸å…³ä¿¡æ¯**:\n"
                for item in relevant_content[:5]:  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ªç›¸å…³é¡¹
                    if item:
                        report += f"- {item}\n"
                report += "\n"

    # ç»“è®º
    report += "---\n\n## ğŸ“Œ ç»“è®º\n\n"
    report += f"âœ… æˆåŠŸè¯»å–äº† {len(file_contents)} ä¸ªæœ¬åœ°æ–‡ä»¶\n"
    report += f"âœ… æ‰€æœ‰æ•°æ®æ¥æºäºæœ¬åœ°MCPæ–‡ä»¶ç³»ç»Ÿï¼Œç¡®ä¿äº†æ•°æ®éšç§\n"
    report += f"âœ… ç ”ç©¶åŸºäºå®é™…çš„æœ¬åœ°æ–‡æ¡£å†…å®¹ï¼Œè€Œéç½‘ç»œæœç´¢ç»“æœ\n\n"

    report += "---\n\n*æœ¬æŠ¥å‘Šç”±MCPæœ¬åœ°æ–‡ä»¶ç ”ç©¶ç³»ç»Ÿç”Ÿæˆ*"

    return report

def main():
    parser = argparse.ArgumentParser(description="åŸºäºMCPçš„æœ¬åœ°æ–‡ä»¶ç ”ç©¶å·¥å…·ï¼ˆå·¥ä½œç‰ˆæœ¬ï¼‰")
    parser.add_argument("question", help="ç ”ç©¶é—®é¢˜æˆ–ä¸»é¢˜")
    parser.add_argument("--docs-path", default="./test_docs", help="è¦ç ”ç©¶çš„æ–‡æ¡£ç›®å½•è·¯å¾„")

    args = parser.parse_args()

    # è¿è¡Œæœ¬åœ°æ–‡ä»¶ç ”ç©¶
    result = asyncio.run(run_mcp_local_research(args.question, args.docs_path))

    if result:
        print("\nâœ… ç ”ç©¶å®Œæˆ!")
    else:
        print("\nâŒ ç ”ç©¶å¤±è´¥!")

if __name__ == "__main__":
    main()